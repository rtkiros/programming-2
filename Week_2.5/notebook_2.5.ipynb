{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd \n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good that in this case you have used a Notebook. That proves that you know when to choose the right tools for the job. I just wonder where all the references to `df` in the cells below come from..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the protein annotation data using Dask Dataframe\n",
    "protien_data = dd.read_csv('/data/dataprocessing/interproscan/all_bacilli.tsv', sep ='\\t', dtype= str, header = None, names = [\"0\", \"1\", \"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_distinct_annotations(df_path):\n",
    "    \"\"\"\n",
    "    Compute the distinct annotations from the protein annotation data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - distinct_annotations (Dask Series): A Dask Series containing the distinct annotations.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Drop duplicate annotations and compute distinct values\n",
    "\n",
    "    # there is no `df`\n",
    "    distinct_annotations = df['11'].drop_duplicates().compute(num_workers=16)\n",
    "    \n",
    "    return distinct_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling distinict annotations\n",
    "distinct_annotations = compute_distinct_annotations(protien_data)\n",
    "print(\"Distinct annotations:\", distinct_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_annotations(df_path):\n",
    "    \"\"\"\n",
    "    Compute the average number of annotations per protein.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - average_annotations (float): The average number of annotations per protein.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the average number of annotations per protein\n",
    "\n",
    "    # there is no `df`\n",
    "    average_annotations = df.groupby('1').size().mean().compute(num_workers=16)\n",
    "    \n",
    "    return average_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_annotations = compute_average_annotations(protien_data)\n",
    "print(\"Average number of annotations per protein:\", average_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_common_go_term(df_path):\n",
    "    \"\"\"\n",
    "    Find the most common Gene Ontology (GO) term from the protein annotation data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - most_common_go_term (str): The most common Gene Ontology (GO) term.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the GO terms and explode them into separate rows\n",
    "    go_terms = df['0'].str.split('|').explode()\n",
    "    \n",
    "    # Find the most common GO term\n",
    "    most_common_go_term = go_terms.value_counts().nlargest(1).compute(num_workers=16).index[0]\n",
    "    \n",
    "    return most_common_go_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_go_term = find_most_common_go_term(protien_data)\n",
    "print(\"Most common GO term:\", most_common_go_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_feature_size(df_path):\n",
    "    \"\"\"\n",
    "    Compute the average size of InterPRO features from the protein annotation data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - average_feature_size (float): The average size of InterPRO features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the feature size and compute the average\n",
    "    df['CustomFeatureSize'] = df['7'].astype(int) - df['6'].astype(int)\n",
    "    average_feature_size = df['CustomFeatureSize'].mean().compute(num_workers=16)\n",
    "\n",
    "    return average_feature_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling average size function\n",
    "average_size = compute_average_feature_size(protien_data)\n",
    "print(\"Average size of Custom InterPRO feature:\", average_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_10_interpro_features(df_path):\n",
    "    \"\"\"\n",
    "    Compute the top 10 most common InterPRO features from the protein annotation data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - top_10_interpro_features (Dask Series): A Dask Series containing the top 10 most common InterPRO features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the top 10 most common InterPRO features\n",
    "    top_10_interpro_features = df['1'].value_counts().nlargest(10).compute(num_workers=16)\n",
    "\n",
    "    return top_10_interpro_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features = compute_top_10_interpro_features(protien_data)\n",
    "print(\"Top 10 most common InterPRO features:\")\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_10_similar_size_features(df_path, similar_size_threshold=0.9):\n",
    "    \"\"\"\n",
    "    Compute the top 10 most common InterPRO features with similar size to the protein from the protein annotation data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "    - similar_size_threshold (float, optional): The threshold for similarity of feature size to protein size. Default is 0.9.\n",
    "\n",
    "    Returns:\n",
    "    - top_10_similar_size_features (Dask Series): A Dask Series containing the top 10 most common InterPRO features with similar size.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the protein size\n",
    "    protein_size = df['2'].astype(int)\n",
    "\n",
    "    # Select InterPRO features with similar size to the protein\n",
    "    similar_size_features = df[abs(df['FeatureSize'] - protein_size) / protein_size <= similar_size_threshold]\n",
    "\n",
    "    # Compute the top 10 most common InterPRO features with similar size\n",
    "    top_10_similar_size_features = similar_size_features['1'].value_counts().nlargest(10).compute(num_workers=16)\n",
    "\n",
    "    return top_10_similar_size_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_similar_size_features = compute_top_10_similar_size_features(protien_data)\n",
    "print(\"Top 10 most common InterPRO features with similar size:\")\n",
    "print(top_10_similar_size_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_top_10_common_and_least_common_words(df_path):\n",
    "    \"\"\"\n",
    "    Compute the top 10 most common and least common words found in the textual annotations of the protein annotation data.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - top_10_most_common_words (list): A list of tuples containing the top 10 most common words and their counts.\n",
    "    - top_10_least_common_words (list): A list of tuples containing the top 10 least common words and their counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the protein annotation data using Dask Dataframe\n",
    "    df = dd.read_csv(df_path)\n",
    "\n",
    "    # Concatenate the textual annotations into a single column\n",
    "    text_annotations = df['3'] + ' ' + df['4'] + ' ' + df['5'] + df['11'] + df['12']\n",
    "\n",
    "    # Preprocess the text annotations\n",
    "    text_annotations = text_annotations.str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(word for annotation in text_annotations for word in annotation.split())\n",
    "\n",
    "    # Get the top 10 most common words\n",
    "    top_10_most_common_words = word_counts.most_common(10)\n",
    "\n",
    "    # Get the top 10 least common words\n",
    "    top_10_least_common_words = word_counts.most_common()[:-11:-1]\n",
    "\n",
    "    return top_10_most_common_words, top_10_least_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_most_common, top_10_least_common = compute_top_10_common_and_least_common_words(protien_data)\n",
    "\n",
    "# Print the top 10 most common words\n",
    "print(\"Top 10 most common words:\")\n",
    "for word, count in top_10_most_common:\n",
    "    print(word, count)\n",
    "\n",
    "# Print the top 10 least common words\n",
    "print(\"\\nTop 10 least common words:\")\n",
    "for word, count in top_10_least_common:\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_10_common_words_similar_size(df_path, similar_size_threshold=0.9):\n",
    "    \"\"\"\n",
    "    Compute the top 10 most common words in the textual annotations of InterPRO features with similar size to the protein.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "    - similar_size_threshold (float, optional): The threshold for similarity of feature size to protein size. Default is 0.9.\n",
    "\n",
    "    Returns:\n",
    "    - top_10_words (list): A list of tuples containing the top 10 most common words and their counts.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the protein annotation data using Dask Dataframe\n",
    "    df = dd.read_csv(df_path)\n",
    "\n",
    "    # Calculate the protein size\n",
    "    protein_size = df['2'].astype(int)\n",
    "\n",
    "    # Select InterPRO features with similar size to the protein\n",
    "    similar_size_features = df[abs(df['FeatureSize'] - protein_size) / protein_size <= similar_size_threshold]\n",
    "\n",
    "    # Get the textual annotation columns for the selected features\n",
    "    text_annotations = similar_size_features['3'] + ' ' + similar_size_features['4'] + ' ' + similar_size_features['5'] + similar_size_features['11'] + similar_size_features['12']\n",
    "    text_annotations = text_annotations.str.lower().str.replace(r'[^a-zA-Z0-9\\s]', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "    # Count the frequency of each word\n",
    "    word_counts = Counter(word for annotation in text_annotations for word in annotation.split())\n",
    "\n",
    "    # Get the top 10 most common words\n",
    "    top_10_words = word_counts.most_common(10)\n",
    "\n",
    "    return top_10_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_common_words_similar_size = compute_top_10_common_words_similar_size(protien_data)\n",
    "\n",
    "# Print the top 10 most common words\n",
    "for word, count in top_10_common_words_similar_size:\n",
    "    print(word, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coefficient_of_correlation(df_path):\n",
    "    \"\"\"\n",
    "    Compute the coefficient of correlation between protein size and the number of features.\n",
    "\n",
    "    Parameters:\n",
    "    - df_path (str): The file path to the protein annotation data in CSV format.\n",
    "\n",
    "    Returns:\n",
    "    - coefficient_of_correlation_result (float): The coefficient of correlation between protein size and the number of features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Calculate the coefficient of correlation\n",
    "    coefficient_of_correlation = df['2'].astype(int).corr(df['7'].astype(int) - df['6'].astype(int))\n",
    "\n",
    "    # Compute the result\n",
    "    coefficient_of_correlation_result = coefficient_of_correlation.compute(num_workers=16)\n",
    "\n",
    "    return coefficient_of_correlation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_result = compute_coefficient_of_correlation(protien_data)\n",
    "print(\"Coefficient of correlation:\", correlation_result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
